{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from sklearn.pipeline import Pipeline\n",
    "import category_encoders as ce\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '../')\n",
    "\n",
    "from src import preprocessing as pp\n",
    "from src import analysis\n",
    "# from src.preprocessing import ReviewsLanguageFilter\n",
    "\n",
    "# Enable module reloading\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "%config InlineBackend.figure_format='retina'\n",
    "plt.rcParams.update({'font.size': 15})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we are going to preprocess our data, so we can use them during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = pd.read_csv('../data/books.csv')\n",
    "reviews = pd.read_csv('../data/reviews.csv')\n",
    "# intr = pd.read_csv('../data/interactions.csv')\n",
    "# authors = pd.read_csv('../data/authors.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Books"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will try to preprocess data from book dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problems needed to be solved by preprocessing are:\n",
    "- drop columns that does not contain any useful information for our task (these are also columns that contain most of the missing values)\n",
    "- replace authors columns by their "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols1 = ['isbn', 'series', 'country_code', 'language_code',\n",
    "              'asin', 'kindle_asin',\n",
    "              'similar_books', 'description', 'format', 'link',\n",
    "              'publisher', 'publication_day', 'isbn13',\n",
    "              'publication_month', 'edition_information', 'publication_year', 'url',\n",
    "              'image_url', 'ratings_count', 'work_id', 'title',\n",
    "              'title_without_series']\n",
    "\n",
    "drop_cols2 = ['popular_shelves', 'authors']\n",
    "\n",
    "tags = ['favorites', 'currently-reading', 'to-read']\n",
    "\n",
    "encoder = ce.OneHotEncoder()\n",
    "\n",
    "books_ppl = Pipeline([\n",
    "    ('DropUnusedCols1', pp.DropColumns(drop_cols1)),\n",
    "    ('SelectTopNPercentileOfBooks', pp.SelectBooksWithNPercentile('text_reviews_count', 0.9)),\n",
    "    ('ExportAuthorsAverageRating', pp.ExportAuthorsAverageRating('authors', 'authors_average_rating', authors)),\n",
    "    ('ExtraxtPopularShelves',pp.ExportBookShelves('popular_shelves', tags)),\n",
    "    ('DropUnusedCols2', pp.DropColumns(drop_cols2)),\n",
    "    ('EncodeCategories', pp.EncodeCategories(encoder))\n",
    "])\n",
    "\n",
    "model = books_ppl.fit(books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_transformed = books_ppl.transform(books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_transformed.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will try to preprocess data from reviews dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problems needed to be solved by preprocessing are:\n",
    "- drop columns, that does not contain any usefull information\n",
    "- since we found out during analysis that longest reviews contain lots of useless data, we will set trashold for max length of review (in number of words)\n",
    "- get rid of reviews that are not in english\n",
    "- remove urls from reviews\n",
    "- remove other special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'book_id', 'review_id', 'rating', 'review_text',\n",
       "       'date_added', 'date_updated', 'read_at', 'started_at', 'n_votes',\n",
       "       'n_comments'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(fit) Drop columns: ['date_added', 'date_updated', 'read_at', 'started_at']\n",
      "(transform) Drop columns: ['date_added', 'date_updated', 'read_at', 'started_at']\n",
      "(fit) Empty values filter\n",
      "(transform) Empty values filter\n",
      "(fit) Text preprocessing\n",
      "(transform) Text preprocessing\n",
      "(fit) Review length filter\n",
      "(transform) Review length filter\n",
      "(fit) Reviews language filter\n"
     ]
    }
   ],
   "source": [
    "drop_cols1 = ['date_added', 'date_updated', 'read_at', 'started_at']\n",
    "\n",
    "reviews_ppl = Pipeline([\n",
    "    ('DropUnusedCols1', pp.DropColumns(drop_cols1)),\n",
    "    ('EmptyValuesFilter', pp.EmptyValuesFilter(['review_text'])),\n",
    "    ('TextPreprocessor', pp.TextPreprocessor('review_text')),\n",
    "    ('ReviewLengthFilter', pp.ReviewLengthFilter('review_text', 0, 2000)),\n",
    "    ('ReviewsLanguageFilter', pp.ReviewsLanguageFilter('review_text', 'en'))\n",
    "])\n",
    "\n",
    "model = reviews_ppl.fit(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(transform) Drop columns: ['date_added', 'date_updated', 'read_at', 'started_at']\n",
      "(transform) Empty values filter\n",
      "(transform) Text preprocessing\n"
     ]
    }
   ],
   "source": [
    "reviews_transformed = reviews_ppl.transform(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_transformed.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(books_transformed, reviews_transformed, on='book_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['rating']\n",
    "\n",
    "X = data.drop(drop_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
